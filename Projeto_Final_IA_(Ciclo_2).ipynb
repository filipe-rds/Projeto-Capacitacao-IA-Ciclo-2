{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67d98YQ9Em9J"
      },
      "source": [
        "# üìú Projeto Final - Capacita√ß√£o IA (Ciclo 2)\n",
        "# üéì Aluno: Filipe da Silva Rodrigues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T3nUxV-Em9L"
      },
      "source": [
        "## üíª Bibliotecas Necess√°rias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xx3sAPU_Em9L"
      },
      "outputs": [],
      "source": [
        "# Tratamento de Dataset e Gr√°ficos\n",
        "from datasets import load_dataset\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Modelos de Treinamento\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "# Multi-layer Perceptron (MLP)\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "# Support Vector Machine\n",
        "from sklearn.svm import SVC, SVR\n",
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier, XGBRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rieolC1PEm9M"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "üëæ **Dataset de Regress√£o - Hugging Face: Einstellung/demo-salaries**\n",
        "\n",
        "Esse dataframe √© um conjunto de dados que cont√©m informa√ß√µes sobre sal√°rios e caracter√≠sticas de diferentes cargos na √°rea de ci√™ncia de dados. As vari√°veis s√£o:\n",
        "\n",
        "- `work_year`: o ano em que o sal√°rio foi reportado (ex: 2023).\n",
        "- `experience_level`: o n√≠vel de experi√™ncia do funcion√°rio (EN = J√∫nior, MI = Pleno, SE = S√™nior, EX = Executivo).\n",
        "- `employment_type`: o tipo de emprego (PT = Meio per√≠odo, FT = Tempo integral, CT = Contrato, FL = Freelance).\n",
        "- `job_title`: o t√≠tulo do cargo do funcion√°rio (ex: Data Scientist, Data Engineer).\n",
        "- `salary`: o sal√°rio anual bruto reportado.\n",
        "- `salary_currency`: a moeda na qual o sal√°rio foi pago (ex: USD, EUR).\n",
        "- `salary_in_usd`: o sal√°rio anual bruto convertido para USD.\n",
        "- `employee_residence`: o pa√≠s de resid√™ncia do funcion√°rio (ex: US, CA, GB).\n",
        "- `remote_ratio`: a propor√ß√£o de trabalho remoto (0 = Presencial, 50 = H√≠brido, 100 = Totalmente remoto).\n",
        "- `company_location`: o pa√≠s onde a empresa est√° localizada.\n",
        "- `company_size`: o tamanho da empresa (S = Pequena, M = M√©dia, L = Grande).\n",
        "\n",
        "‚úÖ **Objetivo:** Prever o sal√°rio anual bruto em USD de acordo com as caracter√≠sticas coletadas.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_F2jeyjEm9M",
        "outputId": "50e652ed-7ad9-49ca-eac7-c8c045500bb3"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/datasets/Einstellung/demo-salaries\n",
        "\n",
        "dataset = load_dataset(\"Einstellung/demo-salaries\")\n",
        "\n",
        "\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('\\nDataset Original:\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "display(dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Criando uma c√≥pia do dataset para efetuar os devidos tratamentos\n",
        "df = pd.DataFrame(dataset).copy()\n",
        "\n",
        "# Normalizando os dados das features na escala (0..1)\n",
        "columns_to_normalize = ['salary_in_usd', 'salary', 'work_year', 'remote_ratio,']\n",
        "df[columns_to_normalize] = MinMaxScaler().fit_transform(df[columns_to_normalize])\n",
        "\n",
        "# Convertendo features categ√≥ricas para n√∫meros com OneHotEncoder\n",
        "categorical_columns = ['sex', 'smoker', 'day', 'time']\n",
        "column_transform = make_column_transformer(\n",
        "    (OneHotEncoder(drop='first'), categorical_columns), remainder='passthrough')\n",
        "df = column_transform.fit_transform(df)\n",
        "columns_names = column_transform.get_feature_names_out()\n",
        "\n",
        "# Transformando o resultado em um DataFrame\n",
        "df = pd.DataFrame(data=df, columns=columns_names)\n",
        "\n",
        "# Renomenado as colunas para melhor entendimento\n",
        "columns = df.columns\n",
        "\n",
        "# Dicion√°rio para mapear as colunas a serem renomeadas\n",
        "rename_mapping = {}\n",
        "\n",
        "for column in columns:\n",
        "    if column.startswith('onehotencoder__'):\n",
        "        new_column_name = column.replace('onehotencoder__', '')\n",
        "        rename_mapping[column] = new_column_name\n",
        "    if column.startswith('remainder__'):\n",
        "        new_column_name = column.replace('remainder__', '')\n",
        "        rename_mapping[column] = new_column_name\n",
        "\n",
        "# print(rename_mapping)\n",
        "\n",
        "# Renomeando as colunas\n",
        "df.rename(columns=rename_mapping, inplace=True)\n",
        "\n",
        "# Exibindo o DataFrame tratado com as colunas renomeadas\n",
        "print('\\nDataset Tratado para Treinamento:\\n')\n",
        "display(df)\n",
        "\n",
        "# Separando os dados para treinamento e teste\n",
        "y = df['tip']  # Coluna 'tip'\n",
        "x = df.drop('tip', axis=1)  # Todas as outras colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LRgfM56Em9N"
      },
      "source": [
        "ü§ñ Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83z0BT-VEm9N",
        "outputId": "222075c4-816c-43a2-f378-6e3cabc3fa4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DT1: 83.765 %\n",
            "DT2: 82.941 %\n",
            "KNN1: 80.588 %\n",
            "KNN2: 80.294 %\n",
            "MLP1: 85.176 %\n",
            "MLP2: 83.235 %\n",
            "SVM1: 78.118 %\n",
            "SVM2: 75.529 %\n",
            "RF: 79.824 %\n",
            "XGB: 82.471 %\n"
          ]
        }
      ],
      "source": [
        "# Inicializando os modelos de treinamento\n",
        "\n",
        "# DT - Decision Tree\n",
        "model_dt1 = DecisionTreeClassifier(criterion='gini', max_depth=5)\n",
        "model_dt2 = DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
        "\n",
        "# KNN - K-Nearest Neighbors\n",
        "model_knn1 = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
        "model_knn2 = KNeighborsClassifier(n_neighbors=10, metric='manhattan')\n",
        "\n",
        "# MLP - Multi-layer Perceptron\n",
        "model_mlp1 = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, activation='relu')\n",
        "model_mlp2 = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1500, activation='tanh')\n",
        "\n",
        "# SVM - Support Vector Machine\n",
        "model_svm1 = SVC(kernel='linear', C=1, gamma='scale')\n",
        "model_svm2 = SVC(kernel='rbf', C=0.1, gamma='scale')\n",
        "\n",
        "# RF - Random Forest\n",
        "model_rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
        "\n",
        "# XGB - XGBoost\n",
        "model_xgb = XGBClassifier(objective='binary:logistic', max_depth=3, learning_rate=0.1)\n",
        "\n",
        "\n",
        "\n",
        "# Treinamento dos modelos e avalia√ß√£o da acur√°cia\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "accuracies = []\n",
        "\n",
        "# N√∫mero de repeti√ß√µes do treinamento\n",
        "n = 10\n",
        "\n",
        "for i in range(n):\n",
        "    # Realizando o Train-Test-Split\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=np.random.randint(1000))\n",
        "\n",
        "    # Treinamento dos modelos\n",
        "    model_dt1.fit(x_train, y_train)\n",
        "    model_dt2.fit(x_train, y_train)\n",
        "\n",
        "    model_knn1.fit(x_train, y_train)\n",
        "    model_knn2.fit(x_train, y_train)\n",
        "\n",
        "    model_mlp1.fit(x_train, y_train)\n",
        "    model_mlp2.fit(x_train, y_train)\n",
        "\n",
        "    model_svm1.fit(x_train, y_train)\n",
        "    model_svm2.fit(x_train, y_train)\n",
        "\n",
        "    model_rf.fit(x_train, y_train)\n",
        "\n",
        "    model_xgb.fit(x_train, y_train)\n",
        "\n",
        "    # Previs√µes para cada modelo\n",
        "    predictions_dt1 = model_dt1.predict(x_test)\n",
        "    predictions_dt2 = model_dt2.predict(x_test)\n",
        "\n",
        "    predictions_knn1 = model_knn1.predict(x_test)\n",
        "    predictions_knn2 = model_knn2.predict(x_test)\n",
        "\n",
        "    predictions_mlp1 = model_mlp1.predict(x_test)\n",
        "    predictions_mlp2 = model_mlp2.predict(x_test)\n",
        "\n",
        "    predictions_svm1 = model_svm1.predict(x_test)\n",
        "    predictions_svm2 = model_svm2.predict(x_test)\n",
        "\n",
        "    predictions_rf = model_rf.predict(x_test)\n",
        "\n",
        "    predictions_xgb = model_xgb.predict(x_test)\n",
        "\n",
        "    # C√°lculo da acur√°cia para cada modelo\n",
        "    acc_dt1 = accuracy_score(y_test, predictions_dt1)\n",
        "    acc_dt2 = accuracy_score(y_test, predictions_dt2)\n",
        "\n",
        "    acc_knn1 = accuracy_score(y_test, predictions_knn1)\n",
        "    acc_knn2 = accuracy_score(y_test, predictions_knn2)\n",
        "\n",
        "    acc_mlp1 = accuracy_score(y_test, predictions_mlp1)\n",
        "    acc_mlp2 = accuracy_score(y_test, predictions_mlp2)\n",
        "\n",
        "    acc_svm1 = accuracy_score(y_test, predictions_svm1)\n",
        "    acc_svm2 = accuracy_score(y_test, predictions_svm2)\n",
        "\n",
        "    acc_rf = accuracy_score(y_test, predictions_rf)\n",
        "\n",
        "    acc_xgb = accuracy_score(y_test, predictions_xgb)\n",
        "\n",
        "    # Armazamento das acur√°cias na lista\n",
        "    accuracies.append([acc_dt1, acc_dt2, acc_knn1, acc_knn2, acc_mlp1, acc_mlp2, acc_svm1, acc_svm2, acc_rf, acc_xgb])\n",
        "\n",
        "\n",
        "# Convertendo a lista para um array numpy para calcular a m√©dia\n",
        "accuracies = np.array(accuracies)\n",
        "\n",
        "# Calculando a m√©dia das acur√°cias para cada modelo\n",
        "average_accuracies = np.mean(accuracies, axis=0)\n",
        "\n",
        "# R√≥tulo com o nome dos modelos\n",
        "model_names = ['DT1', 'DT2', 'KNN1', 'KNN2', 'MLP1', 'MLP2', 'SVM1', 'SVM2', 'RF', 'XGB']\n",
        "\n",
        "# Apresentar a m√©dia das execu√ß√µes dos resultados de acur√°cia de todos os modelos\n",
        "for model, acc in zip(model_names, average_accuracies):\n",
        "    print(f'{model}: {acc*100:.3f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctiG4OLS83a7"
      },
      "source": [
        "## üß™ Experimentos no MLFLOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA1lhima83bB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
